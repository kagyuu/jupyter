{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn の iris データを読み込む\n",
    "* 機械学習の基本のキ → 教師データを学習用と、検証用に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:150 = train:120 + test:30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "# データセットのロード\n",
    "# iris.data = [(がく片の長さ , がく片の幅 , 花びらの長さ , 花びらの幅)]\n",
    "iris = datasets.load_iris()\n",
    "x_vals = np.array([x[0:3] for x in iris.data])\n",
    "y_vals = np.array([x[3] for x in iris.data])\n",
    "\n",
    "data_size = len(x_vals)\n",
    "train_size = int(data_size * 0.8)\n",
    "test_size = data_size - train_size\n",
    "\n",
    "x_train = x_vals[0:train_size]\n",
    "y_train = y_vals[0:train_size]\n",
    "\n",
    "x_test = x_vals[train_size:data_size]\n",
    "y_test = y_vals[train_size:data_size]\n",
    "\n",
    "print (\"total:{} = train:{} + test:{}\".format(data_size, len(x_train), len(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共通関数の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isDebugEnabled = True\n",
    "def debug(msg, *args) :\n",
    "    if isDebugEnabled :\n",
    "        print(msg.format(*args))\n",
    "\n",
    "def sigmoid(x) :\n",
    "    \"\"\"\n",
    "    Sigmoid (シグモイド関数)\n",
    "    @param x\n",
    "    @return sigmoid(x)\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * x))\n",
    "\n",
    "def relu(x) :\n",
    "    \"\"\"\n",
    "     Rectified Linear Unit (正規化線形関数).\n",
    "    @param x\n",
    "    @return max(0,x)\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def identity_mapping(x) :\n",
    "    \"\"\"\n",
    "    恒等写像です.\n",
    "    @param x \n",
    "    @return xをそのまま返します\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid (シグモイド関数)の導関数\n",
    "    @param x\n",
    "    @return sigmoid'(x)\n",
    "    \"\"\"\n",
    "    dx = (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "    return dx\n",
    "\n",
    "def d_relu(x):\n",
    "    \"\"\"\n",
    "     ReLuの導関数.\n",
    "    @param x\n",
    "    @return relu'(x)\n",
    "    \"\"\"\n",
    "    return np.where( x > 0, 1, 0)\n",
    "\n",
    "def least_square(d, y):\n",
    "    \"\"\"\n",
    "    自乗誤差を求めます.\n",
    "    @param d 教師データ(expected)\n",
    "    @param y 予想(actual)\n",
    "    \"\"\"\n",
    "    return np.sum(np.square(d - y)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク作成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(in_size, out_size) :\n",
    "    \"\"\"\n",
    "    1レイヤ分をランダムに初期化します.\n",
    "    @param in_size 入力サイズ\n",
    "    @param out_size 出力サイズ\n",
    "    @return w 重み行列\n",
    "    @return b バイアス\n",
    "    \"\"\"\n",
    "    w = np.random.rand(out_size, in_size)\n",
    "    b = np.random.rand(out_size)\n",
    "    return w,b\n",
    "\n",
    "def create_network(*units) :\n",
    "    \"\"\"\n",
    "    nレイヤ分のネットワークを作成します\n",
    "    @param *units 中間層のサイズを可変引数で指定します\n",
    "    @return w 重み行列\n",
    "    @return b バイアス\n",
    "    \"\"\"\n",
    "    w_lst = []\n",
    "    b_lst = []\n",
    "    for layer in range(0, len(units) - 1) :\n",
    "        in_size = units[layer]\n",
    "        out_size = units[layer+1]\n",
    "        w,b = create_layer(in_size, out_size)\n",
    "        w_lst.append(w)\n",
    "        b_lst.append(b)\n",
    "    return w_lst, b_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 順伝搬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "D (expect) : 0.2, Y (actual) : [[13.04852271  8.67349662 13.87669814]], E (error): 211.96837640412718\n",
      "U (mid layers) : [array([[6.60820352, 4.21302467, 7.06160156],\n",
      "       [6.79506478, 4.39988592, 7.24846282],\n",
      "       [6.83341618, 4.43823733, 7.28681422]]), array([[13.04852271,  8.67349662, 13.87669814]])]\n",
      "----------\n",
      "E (error): 8390.597265775443\n"
     ]
    }
   ],
   "source": [
    "def forward(x,w,b,func) :\n",
    "    \"\"\"\n",
    "    順伝搬します.\n",
    "    \n",
    "    z(0) = x\n",
    "    for l = 1 to L\n",
    "      u(l) = W(l) ・ z(l-1) + b(l)\n",
    "      z(l) = relu( u(l) )\n",
    "    y = func( z(L) )\n",
    "    \n",
    "    @param x 入力データ　(複数のデータを同時に投入できる)\n",
    "    @param w 重み行列\n",
    "    @param b バイアス\n",
    "    @param func 出力層の活性化関数\n",
    "    @return y 出力\n",
    "    @return u 中間層の計算結果\n",
    "    \"\"\"\n",
    "    #　投入されたミニバッチの大きさを取得\n",
    "    batch_size = 1 if 1 == len(x.shape) else x.shape[1] \n",
    "    debug(\"batch size = {}\", batch_size)\n",
    "    \n",
    "    z = x\n",
    "    u_lst = []\n",
    "    for layer in range(0, len(w)) :\n",
    "        debug(\"layer [{}] w = \\n{}\", layer, w[layer])\n",
    "        debug(\"layer [{}] z = {}\", layer, z)\n",
    "        debug(\"layer [{}] b = {}\", layer, b[layer])\n",
    "        \n",
    "        # ミニバッチで、バイアスを計算するために、各行がバイアスで、ミニバッチの大きさ\n",
    "        # 分だけ列数がある bias 　行列を作る。作り方は、\n",
    "        # 対角成分がバイアスな行列 ・ 行数バイアスの大きさ ×列数ミニバッチの大きさで成分が1な行列 =\n",
    "        #  [\n",
    "        #   [b1 b1 b1 ... b1]\n",
    "        #   [b2 b2 b2 ... b2]\n",
    "        #   [b3 b3 b3 ... b3]\n",
    "        # ]\n",
    "        bias_size = b[layer].shape[0]\n",
    "        bias = (np.identity(bias_size) * b[layer]).dot( np.ones((bias_size, batch_size)))\n",
    "        \n",
    "        u = w[layer].dot(z) + bias\n",
    "        u_lst.append(u)\n",
    "        z = func(u)\n",
    "        debug(\"layer [{}] output = {}\", layer, z)\n",
    "    # 出力は恒等写像とする\n",
    "    y = identity_mapping(z)\n",
    "    return y, u_lst\n",
    "\n",
    "# 確認用ネットワーク作成\n",
    "w,b = create_network(3,3,1)\n",
    "\n",
    "# 順伝搬の動作確認1 (1データの投入)\n",
    "print(\"----------\")\n",
    "# 0 番目のデータを初期ネットワークで順伝搬してみます\n",
    "# 出力層の活性化関数は 恒等写像 (identity_mapping)\n",
    "y, u = forward(x_train[0], w, b, identity_mapping)\n",
    "print(\"D (expect) : {}, Y (actual) : {}, E (error): {}\".format(y_train[0], y, least_square(y_train[0], y)))\n",
    "print(\"U (mid layers) : {}\".format(u))\n",
    "\n",
    "# 順伝搬の動作確認2 (データのバッチ投入)\n",
    "print(\"----------\")\n",
    "isDebugEnabled = False\n",
    "y,u = forward(x_train.T, w, b, identity_mapping)\n",
    "print(\"E (error): {}\".format(least_square(y_train, y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逆伝搬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backword(w,b,u,y,d,func) :\n",
    "    \"\"\"\n",
    "    逆伝搬します.\n",
    "    @param w 重み行列\n",
    "    @param b バイアス\n",
    "    @return u 中間層の計算結果\n",
    "    @return y 出力\n",
    "    @return d 教師値\n",
    "    @param func 出力層の活性化関数の導関数\n",
    "    @return w 更新後の重み行列\n",
    "    @return b 更新後のバイアス\n",
    "    \"\"\"\n",
    "    # TODO Implement me!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
